{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FD2425\n",
    "Jorge Machado 21181\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVR, NuSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>transmission</th>\n",
       "      <th>color</th>\n",
       "      <th>odometer_value</th>\n",
       "      <th>year_produced</th>\n",
       "      <th>engine_fuel</th>\n",
       "      <th>engine_has_gas</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>body_type</th>\n",
       "      <th>has_warranty</th>\n",
       "      <th>state</th>\n",
       "      <th>drivetrain</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>is_exchangeable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subaru</td>\n",
       "      <td>Outback</td>\n",
       "      <td>automatic</td>\n",
       "      <td>silver</td>\n",
       "      <td>190000</td>\n",
       "      <td>2010</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>False</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2.50</td>\n",
       "      <td>universal</td>\n",
       "      <td>False</td>\n",
       "      <td>owned</td>\n",
       "      <td>all</td>\n",
       "      <td>10900.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subaru</td>\n",
       "      <td>Outback</td>\n",
       "      <td>automatic</td>\n",
       "      <td>blue</td>\n",
       "      <td>290000</td>\n",
       "      <td>2002</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>False</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>3.00</td>\n",
       "      <td>universal</td>\n",
       "      <td>False</td>\n",
       "      <td>owned</td>\n",
       "      <td>all</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subaru</td>\n",
       "      <td>Forester</td>\n",
       "      <td>automatic</td>\n",
       "      <td>red</td>\n",
       "      <td>402000</td>\n",
       "      <td>2001</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>False</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2.50</td>\n",
       "      <td>suv</td>\n",
       "      <td>False</td>\n",
       "      <td>owned</td>\n",
       "      <td>all</td>\n",
       "      <td>2800.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subaru</td>\n",
       "      <td>Impreza</td>\n",
       "      <td>mechanical</td>\n",
       "      <td>blue</td>\n",
       "      <td>10000</td>\n",
       "      <td>1999</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>False</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>3.00</td>\n",
       "      <td>sedan</td>\n",
       "      <td>False</td>\n",
       "      <td>owned</td>\n",
       "      <td>all</td>\n",
       "      <td>9999.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>automatic</td>\n",
       "      <td>black</td>\n",
       "      <td>280000</td>\n",
       "      <td>2001</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>False</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2.50</td>\n",
       "      <td>universal</td>\n",
       "      <td>False</td>\n",
       "      <td>owned</td>\n",
       "      <td>all</td>\n",
       "      <td>2134.11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  manufacturer_name model_name transmission   color  odometer_value  \\\n",
       "0            Subaru    Outback    automatic  silver          190000   \n",
       "1            Subaru    Outback    automatic    blue          290000   \n",
       "2            Subaru   Forester    automatic     red          402000   \n",
       "3            Subaru    Impreza   mechanical    blue           10000   \n",
       "4            Subaru     Legacy    automatic   black          280000   \n",
       "\n",
       "   year_produced engine_fuel  engine_has_gas engine_type  engine_capacity  \\\n",
       "0           2010    gasoline           False    gasoline             2.50   \n",
       "1           2002    gasoline           False    gasoline             3.00   \n",
       "2           2001    gasoline           False    gasoline             2.50   \n",
       "3           1999    gasoline           False    gasoline             3.00   \n",
       "4           2001    gasoline           False    gasoline             2.50   \n",
       "\n",
       "   body_type  has_warranty  state drivetrain  price_usd  is_exchangeable  \n",
       "0  universal         False  owned        all   10900.00            False  \n",
       "1  universal         False  owned        all    5000.00             True  \n",
       "2        suv         False  owned        all    2800.00             True  \n",
       "3      sedan         False  owned        all    9999.00             True  \n",
       "4  universal         False  owned        all    2134.11             True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with the specified columns\n",
    "df = pd.read_csv('./cars.csv', usecols=['manufacturer_name', 'model_name', 'transmission', 'color', \n",
    "                                        'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas', \n",
    "                                        'engine_type', 'engine_capacity', 'body_type', 'has_warranty', \n",
    "                                        'state', 'drivetrain', 'price_usd', 'is_exchangeable'])\n",
    "\n",
    "# Remove rows with NaN in any column\n",
    "df = df.dropna().copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       odometer_value  year_produced  engine_capacity  price_usd\n",
      "count        38521.00       38521.00         38521.00   38521.00\n",
      "mean        248910.07        2002.94             2.06    6637.16\n",
      "std         136059.50           8.06             0.67    6425.20\n",
      "min              0.00        1942.00             0.20       1.00\n",
      "25%         158000.00        1998.00             1.60    2100.00\n",
      "50%         250000.00        2003.00             2.00    4800.00\n",
      "75%         325000.00        2009.00             2.30    8950.00\n",
      "max        1000000.00        2019.00             8.00   50000.00 \n",
      "\n",
      "(38521, 16) \n",
      "\n",
      "\n",
      "Index(['manufacturer_name', 'model_name', 'transmission', 'color',\n",
      "       'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas',\n",
      "       'engine_type', 'engine_capacity', 'body_type', 'has_warranty', 'state',\n",
      "       'drivetrain', 'price_usd', 'is_exchangeable'],\n",
      "      dtype='object') \n",
      "\n",
      "\n",
      "manufacturer_name    0\n",
      "model_name           0\n",
      "transmission         0\n",
      "color                0\n",
      "odometer_value       0\n",
      "year_produced        0\n",
      "engine_fuel          0\n",
      "engine_has_gas       0\n",
      "engine_type          0\n",
      "engine_capacity      0\n",
      "body_type            0\n",
      "has_warranty         0\n",
      "state                0\n",
      "drivetrain           0\n",
      "price_usd            0\n",
      "is_exchangeable      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.describe(), \"\\n\")\n",
    "print(df.shape, \"\\n\\n\")\n",
    "print (df.columns, \"\\n\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['price_usd','year_produced', 'odometer_value', 'engine_capacity',]\n",
    "categorical_cols = ['model_name', 'has_warranty', 'is_exchangeable','transmission', 'color', 'engine_fuel','state', 'drivetrain', 'engine_type', 'body_type', 'engine_has_gas', 'manufacturer_name']\n",
    "\n",
    "# Apply StandardScaler to numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Apply LabelEncoder or OneHotEncoder to categorical columns\n",
    "for col in categorical_cols:\n",
    "    # Using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection for modeling\n",
    "X = df[['manufacturer_name','model_name', 'year_produced', 'odometer_value', 'color', 'transmission', 'engine_fuel','engine_type',\n",
    "       'engine_capacity', 'body_type', 'has_warranty', 'state',\n",
    "       'drivetrain', 'price_usd', 'is_exchangeable' ]]\n",
    "\n",
    "y = df['price_usd']  # Target variable\n",
    "\n",
    "# Encode categorical features\n",
    "X = pd.get_dummies(X, columns=['manufacturer_name','model_name', 'year_produced', 'odometer_value', 'color', 'transmission', 'engine_fuel','engine_type',\n",
    "       'engine_capacity', 'body_type', 'has_warranty', 'state',\n",
    "       'drivetrain', 'price_usd', 'is_exchangeable' ], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é para seguir a lógica de 60 - 20 - 20, na função trans_test_split foi dado o parametro 0.20 representando então os 20%\n",
    "\n",
    "\n",
    "represent the proportion of the dataset to include in the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets without stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.60, random_state=50)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=50)\n",
    "\n",
    "\n",
    "# Print the shapes of the splits to verify\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Validation set shape:\", x_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Regression = learn f with continuous output values -> car value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "#model = DecisionTreeRegressor()\n",
    "#model = RandomForestRegressor()\n",
    "#model = NuSVR()\n",
    "#model = LinearSVR()\n",
    "#model = KNeighborsRegressor()\n",
    "#model = AdaBoostRegressor()\n",
    "#model = MLPRegressor()\n",
    "\n",
    "# Fit the model using the correct training split\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate using X_test (testing set)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions to verify\n",
    "print(\"Predictions:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "for i in range(8):\n",
    "    if i == 0:\n",
    "        model = LinearRegression()\n",
    "        \n",
    "        # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    elif i == 1:\n",
    "        model = DecisionTreeRegressor()\n",
    "        \n",
    "        # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    elif i == 2: # ESTE FOI O MELHOR DE ACORDO COM O CENAS DE ESCOLHA\n",
    "        model = RandomForestRegressor()\n",
    "        \n",
    "        # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    elif i == 3:\n",
    "        model = NuSVR()\n",
    "        \n",
    "        # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    elif i == 4:\n",
    "        model = LinearSVR()\n",
    "                # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    elif i == 5:\n",
    "        model = KNeighborsRegressor()\n",
    "        \n",
    "                # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "    elif i == 6:\n",
    "        \n",
    "        model = AdaBoostRegressor()\n",
    "                # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    elif i == 7:\n",
    "        model = MLPRegressor()\n",
    "                # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "        \n",
    "    else:\n",
    "        model = SGDRegressor(max_iter=300000)\n",
    "                # Fit the model using the correct training split\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluate using X_test (testing set)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Print predictions to verify\n",
    "        print(\"Predictions:\", y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas utilizadas para a regressão\n",
    "\n",
    "# MSE – Mean Squared error [1]\n",
    "Mede a diferença média quadrática entre os valores previstos e os valores reais no conjunto de dados.\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "- Fornece uma medida abrangente da precisão do modelo.\n",
    "- Sensível tanto a grandes quanto a pequenos erros.\n",
    "- Fácil de calcular e interpretar.\n",
    "\n",
    "**Limitações:**\n",
    "\n",
    "- Pode ser fortemente influenciado por outliers.\n",
    "- Penaliza erros grandes de forma desproporcional, o que pode nem sempre ser desejável.\n",
    "\n",
    "# MAE – Mean Absolute Error [2]\n",
    "O Erro Médio Absoluto calcula a diferença média entre os valores calculados e os valores reais.\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "- Interpretabilidade: MAE fornece uma medida direta do erro médio, calculando a diferença absoluta média entre os valores previstos e os valores reais. Por exemplo, um MAE de 5 indica que as previsões, em média, desviam-se em 5 unidades dos valores reais.\n",
    "- Robustez a Outliers: MAE é resiliente a outliers, tratando todos os erros de forma igual. Ao contrário do Erro Quadrático Médio (MSE), que penaliza discrepâncias maiores de forma mais intensa, o MAE mantém estabilidade e confiabilidade quando os conjuntos de dados incluem outliers.\n",
    "- Aplicação Prática: MAE é útil em cenários do mundo real onde os custos de erro são lineares, como previsão de demanda ou estimativa de preços de imóveis. Ele oferece insights sobre os tamanhos médios dos erros, tornando-se uma métrica preferida para avaliar a qualidade da previsão com base no erro absoluto em vez do erro relativo.\n",
    "- Penalidade Linear: A natureza linear do MAE significa que o impacto de cada erro na aprendizagem do modelo é diretamente proporcional à sua magnitude. Isso permite que o modelo minimize os erros médios sem focar desproporcionalmente em discrepâncias maiores, garantindo um desempenho equilibrado em todos os pontos de dados.\n",
    "\n",
    "# MAPE – Mean Absolute Percentage Error [3]\n",
    "- O termo MAPE determina quão melhor é a precisão da nossa previsão.\n",
    "- O melhor valor para MAPE é 0, enquanto um valor mais alto indica que as previsões não são precisas o suficiente. No entanto, o quão grande deve ser um valor MAPE para ser considerado uma previsão ineficiente depende do caso de uso.\n",
    "\n",
    "# MDAE – Median Absolute Error [4]\n",
    "A principal vantagem de usar essa métrica é sua forte resiliência a outliers.\n",
    "\n",
    "[1] `https://www.geeksforgeeks.org/mean-squared-error/`  \n",
    "[2] `https://www.geeksforgeeks.org/how-to-calculate-mean-absolute-error-in-python/`  \n",
    "[3] `https://www.geeksforgeeks.org/how-to-calculate-mape-in-python/`  \n",
    "[4] `https://insidelearningmachines.com/median_absolute_error/` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "mdae = metrics.median_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute Percentage Error:\", mape)\n",
    "print(\"Median Absolute Error:\", mdae)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy predictor for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset with the specified columns\n",
    "df = pd.read_csv('./cars.csv', usecols=['manufacturer_name', 'model_name', 'transmission', 'color', \n",
    "                                        'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas', \n",
    "                                        'engine_type', 'engine_capacity', 'body_type', 'has_warranty', \n",
    "                                        'state', 'drivetrain', 'price_usd', 'is_exchangeable'])\n",
    "\n",
    "# Remove rows with NaN in any column\n",
    "df = df.dropna().copy()\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "df['log_price_usd'] = np.log1p(df['price_usd'])\n",
    "\n",
    "# Sample the data (e.g., 10% of the original data)\n",
    "df_sample = df.sample(frac=0.7, random_state=50)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_sample.drop(['price_usd', 'log_price_usd'], axis=1)\n",
    "y = df_sample['log_price_usd']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display all the evaluated models\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta quantidade de features usecols=['manufacturer_name', 'model_name', 'transmission', 'color', \n",
    "                                        'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas', \n",
    "                                        'engine_type', 'engine_capacity', 'body_type', 'has_warranty', \n",
    "                                        'state', 'drivetrain', 'price_usd', 'is_exchangeable']\n",
    "\n",
    "\n",
    "e utilizando o lazy regressor, o melhor modelo para este caso foi o LGBMRegressor, no entanto os valores relativos ao RMSE não foram muito positivos visto que 0.45 é um valor alto.\n",
    "\n",
    "Então o passo seguinte foi pegar neste modelo e testar com diferentes features para averiguar qual é o melhor conjunto de features para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1562\n",
      "[LightGBM] [Info] Number of data points in the train set: 18489, number of used features: 781\n",
      "[LightGBM] [Info] Start training from score -0.004056\n",
      "Predictions: [ 0.14639887 -0.85138506  0.73788992 ...  1.00598642  1.08038578\n",
      " -0.24759172]\n",
      "\n",
      "\n",
      "Resultado do LGBMRegressor\n",
      "\n",
      "Mean Squared Error: 0.12684682731559532\n",
      "Mean Absolute Error: 0.20490381871965732\n",
      "Mean Absolute Percentage Error: 0.893551941079969\n",
      "Median Absolute Error: 0.1243998135330791\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Split the data into training and testing sets without stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.60, random_state=50)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=50)\n",
    "\n",
    "model = LGBMRegressor()\n",
    "\n",
    "\n",
    "# Fit the model using the correct training split\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate using X_test (testing set)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions to verify\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "mdae = metrics.median_absolute_error(y_test, y_pred)\n",
    "\n",
    "print (\"\\n\\nResultado do LGBMRegressor\\n\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute Percentage Error:\", mape)\n",
    "print(\"Median Absolute Error:\", mdae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizar diferentes pca\n",
    "para classificacao fazer histograma com os diferentes preços de carros e criar classes com base num range de preços por exemplo de 0 a 10000, 10001 a 20000, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the same columns are present in the training and testing sets\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Function to apply PCA and train the regressor model\n",
    "def apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Train the regressor model (example: LGBMRegressor)\n",
    "    model = LGBMRegressor(random_state=42)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    print(f\"Results for PCA with {n_components} components:\")\n",
    "    print(f\"R-Squared: {r2_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Apply PCA with different components and train the model\n",
    "apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components=0.95)\n",
    "apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components=10)\n",
    "apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
