{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FD2425\n",
    "Jorge Machado 21181\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVR, NuSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, median_absolute_error,r2_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy Predictor Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with the specified columns\n",
    "df = pd.read_csv('./cars.csv')\n",
    "\n",
    "# Remove rows with NaN in any column\n",
    "df = df.dropna().copy()\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Sample the data (e.g., 10% of the original data)\n",
    "df_sample = df.sample(frac=0.5, random_state=50)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_sample.drop(['price_usd'], axis=1)\n",
    "y = np.log1p(df_sample['price_usd'])  # Use log-transformed target for training\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor()\n",
    "\n",
    "# Fit and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display all the evaluated models\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Regression = learn f with continuous output values -> car value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with the specified columns\n",
    "df = pd.read_csv('./cars.csv', usecols=['manufacturer_name', 'model_name', 'transmission', 'color', \n",
    "                                        'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas', \n",
    "                                        'engine_type', 'engine_capacity', 'body_type', 'has_warranty', \n",
    "                                        'state', 'drivetrain', 'price_usd', 'is_exchangeable'])\n",
    "\n",
    "# Remove rows with NaN in any column\n",
    "df = df.dropna().copy()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe(), \"\\n\")\n",
    "print(df.shape, \"\\n\\n\")\n",
    "print (df.columns, \"\\n\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Tests**\n",
    "\n",
    "using all of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode columns with many unique values\n",
    "label_encode_columns = ['manufacturer_name', 'model_name', 'transmission', 'color', 'body_type', 'drivetrain','engine_fuel']\n",
    "label_encoders = {}\n",
    "\n",
    "\n",
    "for col in label_encode_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# One-hot encode the remaining categorical variables\n",
    "df = pd.get_dummies(df, columns=[col for col in df.columns if df[col].dtype == 'object' and col not in label_encode_columns], drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(['price_usd'], axis=1)\n",
    "Y = np.log1p(df['price_usd'])  # target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE in percentage\n",
    "    return r2, mae, mse, rmse, mape\n",
    "\n",
    "# Loop through different models\n",
    "for i in range(1, 4):\n",
    "    if i == 1:\n",
    "        model = LGBMRegressor()\n",
    "        model_name = \"LGBMRegressor\"\n",
    "    \n",
    "    elif i == 2:\n",
    "        model = HistGradientBoostingRegressor()\n",
    "        model_name = \"HistGradientBoostingRegressor\"\n",
    "    elif i == 3:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model_name = \"GradientBoostingRegressor\"\n",
    "\n",
    "\n",
    "    model.fit(X_train, Y_train)  # Train model\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_test = np.expm1(model.predict(X_test))  # Convert predictions back to original scale (if log-transformed)\n",
    "   \n",
    "    \n",
    "    # Evaluate on test set\n",
    "    r2_test, mae_test, mse_test, rmse_test, mape_test = calculate_metrics(Y_test, y_pred_test)\n",
    "\n",
    "    # Resultados Teste\n",
    "    print(f\"Results for {model_name} (Test Set):\\n\")\n",
    "    print(f\"Predicted Tests Price {y_pred_test}\\n\")\n",
    "    print(f\"R²: {r2_test:.4f}\")\n",
    "    print(f\"MAE: {mae_test:.4f}\")\n",
    "    print(f\"MSE: {mse_test:.4f}\")\n",
    "    print(f\"RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"MAPE: {mape_test:.4f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 30816, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 8.349716\n",
      "Resultado do LGBMRegressor\n",
      "\n",
      "R²: 0.8938\n",
      "MAE: 6475.2391\n",
      "MSE: 77654908.1405\n",
      "RMSE: 8812.2022\n",
      "MAPE: 71458.1733%\n",
      "Resultado do HistGradientBoostingRegressor\n",
      "\n",
      "R²: 0.8928\n",
      "MAE: 6469.8658\n",
      "MSE: 77487964.1691\n",
      "RMSE: 8802.7248\n",
      "MAPE: 71404.5718%\n",
      "Resultado do GradientBoostingRegressor\n",
      "\n",
      "R²: 0.8696\n",
      "MAE: 6341.2730\n",
      "MSE: 72701437.4775\n",
      "RMSE: 8526.5138\n",
      "MAPE: 70172.8011%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Label encode columns with many unique values\n",
    "label_encode_columns_2 = ['manufacturer_name', 'model_name', 'transmission', 'color', \n",
    "                                        'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas', \n",
    "                                        'engine_type', 'engine_capacity', 'body_type', 'has_warranty', \n",
    "                                        'state', 'drivetrain',  'is_exchangeable']\n",
    "label_encoders_2 = {}\n",
    "\n",
    "\n",
    "for col in label_encode_columns_2:\n",
    "    le_2 = LabelEncoder()\n",
    "    df[col] = le_2.fit_transform(df[col])\n",
    "    label_encoders_2[col] = le_2\n",
    "\n",
    "# One-hot encode the remaining categorical variables\n",
    "df = pd.get_dummies(df, columns=[col for col in df.columns if df[col].dtype == 'object' and col not in label_encode_columns_2], drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(['price_usd'], axis=1)\n",
    "Y = np.log1p(df['price_usd'])  # target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # MAPE in percentage\n",
    "    return r2, mae, mse, rmse, mape\n",
    "\n",
    "\n",
    "for i in range(1, 4):\n",
    "    if i == 1:\n",
    "        model = LGBMRegressor()\n",
    "        model_name = \"LGBMRegressor\"\n",
    "    elif i == 2:\n",
    "        model = HistGradientBoostingRegressor()\n",
    "        model_name = \"HistGradientBoostingRegressor\"\n",
    "    elif i == 3:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model_name = \"GradientBoostingRegressor\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = np.expm1(model.predict(X_test))  # Convert predictions back to USD\n",
    "    r2, mae, mse, rmse, mape = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nResultado do {model_name}\")\n",
    "    print(f\"R²: {model.score(X_test, y_test):.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thrid Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().copy()\n",
    "\n",
    "# Feature selection\n",
    "X = df[['manufacturer_name', 'model_name', 'year_produced', 'odometer_value', 'color', 'transmission', 'engine_fuel', \n",
    "        'engine_capacity', 'drivetrain']]\n",
    "\n",
    "# Target variable with log transformation\n",
    "y = np.log1p(df['price_usd'])\n",
    "\n",
    "# Encode categorical features correctly (avoid encoding numeric features)\n",
    "categorical_features = ['manufacturer_name', 'model_name', 'color', 'transmission', 'engine_fuel', 'drivetrain']\n",
    "X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Train-test split (correct order)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.6, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Replace spaces in feature names with underscores\n",
    "X_train.columns = X_train.columns.str.replace(' ', '_')\n",
    "X_test.columns = X_test.columns.str.replace(' ', '_')\n",
    "x_train.columns = x_train.columns.str.replace(' ', '_')\n",
    "x_val.columns = x_val.columns.str.replace(' ', '_')\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Fit model on training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = np.expm1(model.predict(X_test))  # Convert predictions back to USD\n",
    "\n",
    "# Check for NaN values in y_test and y_pred\n",
    "nan_indices = np.isnan(y_test) | np.isnan(y_pred)\n",
    "\n",
    "# Remove NaN values\n",
    "y_test_clean = y_test[~nan_indices]\n",
    "y_pred_clean = y_pred[~nan_indices]\n",
    "\n",
    "# Calculate r2_score\n",
    "r2 = r2_score(y_test_clean, y_pred_clean)\n",
    "mae = mean_absolute_error(y_test_clean, y_pred_clean)\n",
    "mse = mean_squared_error(y_test_clean, y_pred_clean)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test_clean - y_pred_clean) / y_test_clean)) * 100  # MAPE in percentage\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\\nResultado do LGBMRegressor\\n\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth Tests**\n",
    " -PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the same columns are present in the training and testing sets\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Function to apply PCA and train the regressor model\n",
    "def apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Train the regressor model (example: LGBMRegressor)\n",
    "    model = LGBMRegressor(random_state=42)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    print(f\"Results for PCA with {n_components} components:\")\n",
    "    print(f\"R-Squared: {r2_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Apply PCA with different components and train the model\n",
    "apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components=0.95)\n",
    "apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components=10)\n",
    "apply_pca_and_train_regressor(X_train, X_test, y_train, y_test, n_components=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas utilizadas para a regressão\n",
    "\n",
    "# MSE – Mean Squared error [1]\n",
    "Mede a diferença média quadrática entre os valores previstos e os valores reais no conjunto de dados.\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "- Fornece uma medida abrangente da precisão do modelo.\n",
    "- Sensível tanto a grandes quanto a pequenos erros.\n",
    "- Fácil de calcular e interpretar.\n",
    "\n",
    "**Limitações:**\n",
    "\n",
    "- Pode ser fortemente influenciado por outliers.\n",
    "- Penaliza erros grandes de forma desproporcional, o que pode nem sempre ser desejável.\n",
    "\n",
    "# MAE – Mean Absolute Error [2]\n",
    "O Erro Médio Absoluto calcula a diferença média entre os valores calculados e os valores reais.\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "- Interpretabilidade: MAE fornece uma medida direta do erro médio, calculando a diferença absoluta média entre os valores previstos e os valores reais. Por exemplo, um MAE de 5 indica que as previsões, em média, desviam-se em 5 unidades dos valores reais.\n",
    "- Robustez a Outliers: MAE é resiliente a outliers, tratando todos os erros de forma igual. Ao contrário do Erro Quadrático Médio (MSE), que penaliza discrepâncias maiores de forma mais intensa, o MAE mantém estabilidade e confiabilidade quando os conjuntos de dados incluem outliers.\n",
    "- Aplicação Prática: MAE é útil em cenários do mundo real onde os custos de erro são lineares, como previsão de demanda ou estimativa de preços de imóveis. Ele oferece insights sobre os tamanhos médios dos erros, tornando-se uma métrica preferida para avaliar a qualidade da previsão com base no erro absoluto em vez do erro relativo.\n",
    "- Penalidade Linear: A natureza linear do MAE significa que o impacto de cada erro na aprendizagem do modelo é diretamente proporcional à sua magnitude. Isso permite que o modelo minimize os erros médios sem focar desproporcionalmente em discrepâncias maiores, garantindo um desempenho equilibrado em todos os pontos de dados.\n",
    "\n",
    "# MAPE – Mean Absolute Percentage Error [3]\n",
    "- O termo MAPE determina quão melhor é a precisão da nossa previsão.\n",
    "- O melhor valor para MAPE é 0, enquanto um valor mais alto indica que as previsões não são precisas o suficiente. No entanto, o quão grande deve ser um valor MAPE para ser considerado uma previsão ineficiente depende do caso de uso.\n",
    "\n",
    "# MDAE – Median Absolute Error [4]\n",
    "A principal vantagem de usar essa métrica é sua forte resiliência a outliers.\n",
    "\n",
    "[1] `https://www.geeksforgeeks.org/mean-squared-error/`  \n",
    "[2] `https://www.geeksforgeeks.org/how-to-calculate-mean-absolute-error-in-python/`  \n",
    "[3] `https://www.geeksforgeeks.org/how-to-calculate-mape-in-python/`  \n",
    "[4] `https://insidelearningmachines.com/median_absolute_error/` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta quantidade de features usecols=['manufacturer_name', 'model_name', 'transmission', 'color', \n",
    "                                        'odometer_value', 'year_produced', 'engine_fuel', 'engine_has_gas', \n",
    "                                        'engine_type', 'engine_capacity', 'body_type', 'has_warranty', \n",
    "                                        'state', 'drivetrain', 'price_usd', 'is_exchangeable']\n",
    "\n",
    "\n",
    "e utilizando o lazy regressor, o melhor modelo para este caso foi o LGBMRegressor, no entanto os valores relativos ao RMSE não foram muito positivos visto que 0.45 é um valor alto.\n",
    "\n",
    "Então o passo seguinte foi pegar neste modelo e testar com diferentes features para averiguar qual é o melhor conjunto de features para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression models, good values for evaluation metrics indicate how well the model is performing. Here are some common metrics and their ideal values:\n",
    "\n",
    "**R-squared (R²):**\n",
    "\n",
    "Definition: Proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "Good Value: Closer to 1. An R² value of 1 indicates that the model explains all the variability of the response data around its mean.\n",
    "Adjusted R-squared:\n",
    "\n",
    "Definition: Adjusted version of R² that accounts for the number of predictors in the model.\n",
    "Good Value: Closer to 1. It adjusts for the number of predictors, so it is more reliable for comparing models with different numbers of predictors.\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "\n",
    "Definition: Average of the absolute errors between predicted and actual values.\n",
    "Good Value: Closer to 0. Lower values indicate better model performance.\n",
    "Mean Squared Error (MSE):\n",
    "\n",
    "Definition: Average of the squared errors between predicted and actual values.\n",
    "Good Value: Closer to 0. Lower values indicate better model performance.\n",
    "\n",
    "\n",
    "**Root Mean Squared Error (RMSE):**\n",
    "\n",
    "Definition: Square root of the average of the squared errors between predicted and actual values.\n",
    "Good Value: Closer to 0. Lower values indicate better model performance.\n",
    "Mean Absolute Percentage Error (MAPE):\n",
    "\n",
    "Definition: Average of the absolute percentage errors between predicted and actual values.\n",
    "Good Value: Closer to 0%. Lower values indicate better model performance.\n",
    "\n",
    "**Akaike Information Criterion (AIC):**\n",
    "\n",
    "Definition: Measure of the relative quality of a statistical model for a given set of data.\n",
    "Good Value: Lower values are better. It balances model fit and complexity.\n",
    "\n",
    "**Bayesian Information Criterion (BIC):**\n",
    "\n",
    "Definition: Similar to AIC but with a higher penalty for models with more parameters.\n",
    "Good Value: Lower values are better. It also balances model fit and complexity.\n",
    "In general, the ideal values for these metrics depend on the specific context and the nature of the data. Comparing these metrics across different models can help you choose the best model for your regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizar diferentes pca\n",
    "para classificacao fazer histograma com os diferentes preços de carros e criar classes com base num range de preços por exemplo de 0 a 10000, 10001 a 20000, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
